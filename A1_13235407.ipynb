{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "A1_13235407.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/casciofil/31005_AdvancedDataAnalytics/blob/master/A1_13235407.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EAyAMHsj4Bi",
        "colab_type": "text"
      },
      "source": [
        "# Draft and Experiment Area"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaV3O7JHj4Bj",
        "colab_type": "text"
      },
      "source": [
        "1. First impression\n",
        "    * What is my chosen paper to read?\n",
        "    * What type of the main contribution the paper has made?\n",
        "        - A theory or proposition (revealing something, from unknown to known)\n",
        "        - A method or algorithm (inventing a technique, from undoable to doable)\n",
        "\n",
        "    * _Before_ reading the main body of the paper, write down your first impression  obtained from its abstract and short introduction.\n",
        "    * Why does the paper attract you, such as, How it surprised you? Why do you think it addresses an important topic that will be helpful in your future study of machine learning?\n",
        "    \n",
        "2. Read the paper abstract and introduction, list here all the notions that you don't know the precise meaning. If you think you have completed your list,  compare the list with people around you who have chosen the same or a similar paper.\n",
        "\n",
        "3. (During the next 7 days) Re-consider the central problem of the paper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLvJ4TVIkD_c",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "1.   The chosen paper is \"Eigenfaces vs Fisherfaces: Recognition Using Class Specific Linear Projection\". The article, published in July 1997, introduces a new algorithm for face recognition that reduces the error rate when working with large variations in lightning and different facial expressions.  \n",
        "\n",
        "\n",
        "*   By reading only the abstract and the introduction of the paper the impression that I got is that, until the introduction of this Fisherfaces method (the one introduced by the paper), there was no other algorithm on the market that was able to perform face recognition when parameters like light conditions and facial expression were altered. \n",
        "The described technique, on the other side, is able to perform such job after applying a process called dimension reduction, which allows to reduce the number of variables considered (lower the dimensions); in this way the technique is insensitive to lighting direction and facial expression.\n",
        "To prove their finding, Belhumer et al., compare their algorithm with three other techniques used until that moment, and they apply all the techniques to two different databases. \n",
        "I believe that even though the method used to prove their method is correct, the fact that the databases used only contain few hundreds of photos each and do not include variations of poses, make the final results debatable.\n",
        "*   This paper caught my interest because, even if it was published over twenty years ago, talks about a topic that became popular and implemented in everyday's technology only a couple of years ago with the introduction of the first smartphones that included this technology as a security feature. Reading that so long ago, engineers were already discussing and programming face recognition algorithms, increased my interest in the topic.\n",
        "---\n",
        "\n",
        "\n",
        "2.   List of the notions that I do not know the precise meaning of:\n",
        "\n",
        "\n",
        "> * **Pattern Classification Approach**: The automated recognition of patterns and regularities in data - The field of pattern recognition is concerned with the automatic discovery of regularities in data through the use of computer alorithms and with the use of these regularities to take actions such as classifying the data into different categories.\n",
        "* **High-Dimensional Space**: Taking an image as example (since the article is based on images). An image is a big collection of pixels, with each pixel representing an intensity in some range. A low-resolution image might be a 32-by-32 pixel thumbnail. Even though it's represented visually as a square, you can imagine stretching it into a line with 1024 = 32x32 pixels. The point is that this image lives in a 1024-dimensional space ℝ¹⁰²⁴.\n",
        "* **Low-Dimensional Subspace**: Dimensionality reduction is frequently employed to map high-dimensional data to a low-dimentional space while retaining as much information as possible. A low-dimensional subspace is therefore a subspace containing as much information as possible of the parent-space but with a lower number of dimensions. \n",
        "* **3D Linear Subspace**: Linear subspace learning algorithms are traditional dimensionality reduction that represent input data as vectors and solve for an optimal linear mapping to a lower-dimensional space. \n",
        "* **Lambertian Surface**: Lambertian reflectance is the property that defines an ideal \"matte\" or diffusely reflecting surface. The apparent brightness of a Lambertian surface to an observer is the same regardless of the observer's angle of view.\n",
        "* **LDA and PCA**: Both LDA and PCA are linear transformation techniques: LDA is a supervised whereas PCA is unsupervised - PCA ignores class labels. \n",
        "* **Within-Class Scatter Matrix & Between-Class Scatter Matrix**: Multi-class LDA is based on the analysis of two scatter matrices: within-class scatter matrix and between-class scatter matrix. Given a set of samples x1, ...., xn, and their class labels y1, ...., yn: The within-class scatter matrix is defined as ![alt text](https://multivariatestatsjl.readthedocs.io/en/latest/_images/math/85d84a834520d9bdf71d7f41808002a340b0307f.png). Here ![alt text](https://multivariatestatsjl.readthedocs.io/en/latest/_images/math/1f3a5ce5322f20d51fa2cea48fdad713f1605c90.png) is the sample mean of the k-th class. The between-class scatter matrix is defined as ![alt text](https://multivariatestatsjl.readthedocs.io/en/latest/_images/math/5b3188ed0004ef307bfe57a9d54f951eec1702cd.png). Here, m is the number of classes, ![alt text](https://multivariatestatsjl.readthedocs.io/en/latest/_images/math/277f94d1e956bc9e9ce769ea72ef7bab2311c440.png) is the overall sample mean, and ![alt text](https://multivariatestatsjl.readthedocs.io/en/latest/_images/math/e99e14a0688fa0dfa34968afad0841ac5c801721.png)\n",
        " is the number of samples in the k-th class.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjwyGyAKj4Bk",
        "colab_type": "text"
      },
      "source": [
        "# Review Report on \"Eigenfaces vs. Fisherfaces: Recognition Using Class Specific Linear Projection\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJA3GU7lj4Bk",
        "colab_type": "text"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nrrt7orks0jZ",
        "colab_type": "text"
      },
      "source": [
        "This report looks into the article \"Eigenfaces vs. Fisherfaces: Recognition Using Class Specific Linear Projection\" written by Peter N. Belhumeur, Joao P. Hespanha, and David J. Kriedgman and published in July 1997. The report investigates the findings of the article while offering a critique point of view about its content, quality, impact on the world, and more.\n",
        "\n",
        "The mentioned paper explores two new algorithms to perform face recognition when, light conditions and facial expressions, are different between the training and the test sets. \n",
        "\n",
        "Ro support their findings, the authors, compare their algorithms with two other methods that were used at the time (Correlation, and Eigenfaces) and use two different databases(from Harvard Robotic Laboratory and from Yale). In addition, the article also explores the possibility that the person wears glasses. Different images alterations techniques have also been used so that the results of specific techniques could be as accurate as possible.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_I8mB4Pbj4Bl",
        "colab_type": "text"
      },
      "source": [
        "## Content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lM3SKp9Aj4Bl",
        "colab_type": "text"
      },
      "source": [
        "The research is about face recognition techniques and how, in some instances, they are not to be considered reliable. In order to support their theory, the authors mention two primary examples that will then be used in the whole article: different light conditions and facial expressions. The paper, in fact, states that all the face recognition techniques used until that moment are not able to recognise the same person when the light direction or intensity changes or, when the person has a different facial expression than the one expected. If it is considered that people's faces are not Lambertian surfaces (the brightness changes depending on the observer point of view) and, produce therefore self-shadowing, the events taken into accounts by the authors are extremely common and, consequently, they must be considered when developing face recognition technologies.\n",
        "\n",
        "To overcome the problem, this article introduces and experiments two new algorithms that, through the use of dimensionality reduction, find a linear projection which is insenstive to the pre-mentioned issues.\n",
        "\n",
        "The problem faced is to identify each face in the test set through the use of a learning set with other photos from the same group of people. The four methods tested are:\n",
        "\n",
        "\n",
        "*   **Correlation**: This is the most direct method for face recognition, extensively described by Brunelli R. and Poggio T., this system is based on creating four masks for each image in the training test representing eyes, nose, mouth, and face. The test photo is then compared with the photo in the training set, and a \"similarity score\" is assigned to each of the faces. The unknown is then classified as the person with the highest \"similarity score.\"\n",
        "\n",
        "*   **Eigenfaces**: This method uses PCA (principal components analysis), a technique for dimensionality reduction, used on a wide set of different human faces to find standardised faces characteristics and save them as an eigenface. The system saves then each photo in the training set as a value corresponding to the weight of contribution that the face gave to the eigenface. To perform a recognition, the test photo is compared to all the weights in the training set to find the closest match (similar to correlation).\n",
        "\n",
        "*   **Linear Subspaces**: This is the first method developed by the authors of the article and tries to fix the first problem: variations in lighting direction. To do so, for each face, three or more photos with different lighting directions have to be used. In this case, the test face corresponds to the face with the \"shortest distance\" when computing distance between the test face and each linear subspace. \n",
        "\n",
        "*   **Fisherfaces**: This method, considered the most accurate, uses the idea that the training set is labeled to perform a better dimensionality reduction and increase the percentage of success in face recognition. Because of this kind of approach, the Firsherfaces method is considered supervised. This solution overcomes both the problems of different lighting directions and facial expressions.\n",
        "\n",
        "The article tests then three different types of problems with all the methods and databases before drawing conclusions. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gk0aNIuYj4Bm",
        "colab_type": "text"
      },
      "source": [
        "## Innovation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amPXUqVfj4Bm",
        "colab_type": "text"
      },
      "source": [
        "The analysed article was published over twenty years ago in 1997. Nowadays face recognition is widely used in a multiple of different daily activities but, at the time of the work, not many people were aware of how developed this technology already was. \n",
        "Starting from the beginning of the 1990s in fact, face recognition started to become a main issue due mostly to its real-world applications. Going back to the year in which the article has been published, the most common and advanced technique used in face recognition was Eigenfaces and template matching; these and other techniques were considered accurate enough, but most computers were not powerful enough to run them smoothly and in real-time.\n",
        "\n",
        "A paper published in 1995 by David Beymer and Tomaso Poggio (MIT professors) is beneficial to understand what face recognition researchers were mostly working on at that time. As highlighted in the analysed article, good progress had been made in those years in recognising frontal and expressionless countenances with artificial lighting conditions. \n",
        "\n",
        "The above-mentioned paper is useful to understand that the problems (lighting conditions and facial expressions) addressed by Belhumeur et al. and mostly solved with the Fisherfaces algorithm were the only two main concerns at that time.\n",
        "\n",
        "\n",
        "It is also possible to deduce that, another concern of the developers working on face recognition at that time, was the ability of the computers to elaborate the amount of data required by the algorithms that were available at that time; this problem, even if with a lower priority, also seems to be treated by the Fisherfaces algorithm through its dimensionality reduction.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fvbf3Q7j4Bn",
        "colab_type": "text"
      },
      "source": [
        "## Technical quality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEuhIZVKj4Bn",
        "colab_type": "text"
      },
      "source": [
        "The authors, in order to support their findings, have performed three different tests using all four different methods. In total two databases have been used: the first database, made available by the Harvard Robotics Laboratory, offers photos of faces where only lighting variations were applied; on the other hand, the second database, released by Yale, includes photos with variations of both lighting conditions and facial expressions.\n",
        "\n",
        "\n",
        "\n",
        "*   **Variation in Lighting**: This experiment has been designed to test the effectiveness of the four algorithms with photos of the same person, in the same position but, with a different light source direction. The Harvard database has been used for this experiment.\n",
        "\n",
        "*   **Variation in Facial Expression, Eye Wear, and Lighting**: This experiment has been designed to test the effectiveness of the four algorithms with photos of different people under different conditions (different facial expressions, beard, glasses, etc.). The database used this time is the one offered by Yale. \n",
        "In this case, photos had been cropped and adjusted to increase the probability of success.\n",
        "\n",
        "*   **Glasses Recognition**: In this experiment, the algorithms had to understand whether the person was wearing glasses or not instead of recognising the identity. Only the PCA (Eigenface) and Fisherfaces methods have been used.\n",
        "\n",
        "Even though the techniques used by the authors might seem correct they have been used under a controlled environment (no background) and without considering that the aspect of a person can change when time passes, even in a short time; these aspects might bring to wrong conclusions on the actual quality of the algorithm. \n",
        "\n",
        "Another problem that the authors underlined is that the databases used to perform the experiments only contain a small number of faces and, therefore, they might not produce accurate results.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c4yIVmAj4Bo",
        "colab_type": "text"
      },
      "source": [
        "## Application and X-factor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEtbxvASj4Bo",
        "colab_type": "text"
      },
      "source": [
        "I believe that the method presented in the paper, is an exciting innovation in the face recognition area because it addresses all the main challenges that the researchers were facing in that field in the period in which this article was published. \n",
        "\n",
        "A strong characteristic of this algorithm is that the developers have analysed the main technologies available on the market at that time and created this new method by implementing all the functionalities that were missing like the different lighting conditions and by improving the aspects that had to be improved such as the speed and the loss of information.\n",
        "\n",
        "Nowadays, the Fisherfaces algorithm is still one of the most popular and effective face-recognition methods and is widely used in a large variety of real-life situations such as security on mobile devices, social media machine learning technologies and airlines at departure gates."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSa5QgZgj4Bp",
        "colab_type": "text"
      },
      "source": [
        "## Presentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBHgthOzj4Bp",
        "colab_type": "text"
      },
      "source": [
        "The article is written in a clear and concise way; it is easy to follow and definitely not hard to understand where the authors drew their conclusions from. The introduction works fine, and it is clear enough even for someone who is reading a face recognition article for the first time.\n",
        "\n",
        "The second part, which explains the methods that will then be used and analysed, is the only part that might result harder to read, in fact, the authors could have used a clearer language in that section.\n",
        "\n",
        "The experiments and their results are also expressed with a simple but precise language that is easy to read. \n",
        "\n",
        "In general, this paper is an interesting way to start reading about face recognition since it offers a range of knowledge in not many pages that is also reasonably easy to understand."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wa1Eb-fSj4Bq",
        "colab_type": "text"
      },
      "source": [
        "## References\n",
        "\n",
        "[RF1][1]: A. Nadian Ghomsheh; A. Talebpour; M. Basseri, Regional Skin detection based on eliminating skin-like Lambertian surfaces\n",
        "\n",
        "[RF2][2]: R. Brunelli; T. Poggio, Face Recognition: Features versus Templates\n",
        "\n",
        "[RF3][3]: M.A. Turk; A.P. Pentland, Face recognition using eigenfaces\n",
        "\n",
        "[RF4][4]: C. Nastar; M. Mitschke, Real-Time Face Recognition Using Feature Combination\n",
        "\n",
        "[RF5][5]: D. Beymer; T. Poggio, Face Recognition From One Example View\n",
        "\n",
        "[RF6][6]: B.W. Yohanes; R.D. Airlangga; I. Setyawan, Real Time Face Recognition Comparison using Fisherfaces and Local Binary Pattern\n",
        "\n",
        "[RF7][7]: Norton, How does facial recognition work?, Not scholastic article but company website\n",
        "\n",
        "[1]:https://ieeexplore-ieee-org.ezproxy.lib.uts.edu.au/stamp/stamp.jsp?tp=&arnumber=5958932\n",
        "\n",
        "\n",
        "[2]:https://ieeexplore-ieee-org.ezproxy.lib.uts.edu.au/stamp/stamp.jsp?tp=&arnumber=254061\n",
        "\n",
        "[3]:https://ieeexplore-ieee-org.ezproxy.lib.uts.edu.au/stamp/stamp.jsp?tp=&arnumber=139758\n",
        "\n",
        "[4]:https://ieeexplore-ieee-org.ezproxy.lib.uts.edu.au/stamp/stamp.jsp?tp=&arnumber=670967\n",
        "\n",
        "[5]:https://ieeexplore-ieee-org.ezproxy.lib.uts.edu.au/stamp/stamp.jsp?tp=&arnumber=466898\n",
        "\n",
        "[6]:https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8528608\n",
        "\n",
        "[7]:https://us.norton.com/internetsecurity-iot-how-facial-recognition-software-works.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vsRJBHldZqJ",
        "colab_type": "text"
      },
      "source": [
        "GitHub link: https://github.com/casciofil/31005_AdvancedDataAnalytics/blob/master/A1_13235407.ipynb"
      ]
    }
  ]
}